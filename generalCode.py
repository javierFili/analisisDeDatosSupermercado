# -*- coding: utf-8 -*-
"""LimpiezaDeDatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yWbql0FnCICYVjMrcFxMTSNi9rqVrKCv

# Importacion del data set
"""

# prompt: conectar con google drive y extraer un archivo .cvs

from google.colab import drive
import pandas as pd

# Montar Google Drive
drive.mount('/content/drive')

# Ruta del archivo CSV en Google Drive
file_path = '/content/drive/MyDrive/ventas_completas.csv'  # Reemplaza 'your_file.csv' con el nombre real del archivo y la ruta correcta

# Leer el archivo CSV usando pandas
try:
  df = pd.read_csv(file_path)
  print("Archivo CSV le√≠do exitosamente.")
  # Ahora puedes trabajar con el DataFrame 'df'
  print(df.head()) # Muestra las primeras filas del DataFrame
except FileNotFoundError:
  print(f"Error: El archivo '{file_path}' no se encontr√≥ en Google Drive.")
except pd.errors.ParserError:
  print(f"Error: No se pudo procesar el archivo '{file_path}' como un archivo CSV v√°lido.")
except Exception as e:
  print(f"Ocurri√≥ un error inesperado: {e}")
df = df.tail(-1)

df.isnull().sum()

df.head(20)

"""# Limpiesa y preprocesamiento

### 1 Limpieza Inicial de Datos
"""

import pandas as pd
import numpy as np

# Convertir fecha_hora a datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])

# Verificar y manejar valores nulos
print(df.isnull().sum())
df = df.dropna(subset=['venta_id', 'fecha_hora', 'total_venta', 'producto_id'])  # Columnas cr√≠ticas

# Manejar clientes an√≥nimos (si aplica)
df['cliente_id'] = df['cliente_id'].fillna(0)

df['cliente_nombre'] = df['cliente_nombre'].fillna('CLIENTE OCASIONAL')
#df = df.dropna(subset=["cliente_nombre"])
df['precio_unitario'] = df["precio_unitario"]*0.20
# Verificar duplicados
df = df.drop_duplicates()

df.head(20)

"""### 2.Ingenier√≠a de Caracter√≠sticas para los Objetivos"""

# Extraer componentes de fecha para an√°lisis temporal
df['fecha'] = df['fecha_hora'].dt.date
df['hora'] = df['fecha_hora'].dt.hour
df['dia_semana'] = df['fecha_hora'].dt.day_name()
df['mes'] = df['fecha_hora'].dt.month
df['trimestre'] = df['fecha_hora'].dt.quarter
df['a√±o'] = df['fecha_hora'].dt.year

# Crear categor√≠as de hora del d√≠a
df['franja_horaria'] = pd.cut(df['hora'],
                             bins=[0, 6, 12, 18, 24],
                             labels=['Madrugada', 'Ma√±ana', 'Tarde', 'Noche'],
                             right=False)

# Clasificaci√≥n ABC de productos (para gesti√≥n de inventario)
ventas_por_producto = df.groupby('producto_id')['cantidad'].sum().sort_values(ascending=False)
ventas_por_producto = ventas_por_producto.reset_index()
ventas_por_producto['porcentaje_acumulado'] = ventas_por_producto['cantidad'].cumsum() / ventas_por_producto['cantidad'].sum() * 100

# Asignar categor√≠as ABC
def clasificar_abc(x):
    if x <= 80:
        return 'A'
    elif x <= 95:
        return 'B'
    else:
        return 'C'

ventas_por_producto['clasificacion_abc'] = ventas_por_producto['porcentaje_acumulado'].apply(clasificar_abc)

# Unir al DataFrame principal
df = df.merge(ventas_por_producto[['producto_id', 'clasificacion_abc']], on='producto_id', how='left')

"""### 3. Validaci√≥n y Consistencia de Datos"""

# Verificar consistencia en c√°lculos num√©ricos
df['subtotal_calculado'] = df['cantidad'] * df['precio_unitario']
inconsistencias = df[abs(df['subtotal'] - df['subtotal_calculado']) > 0.01]
if not inconsistencias.empty:
    print(f"Advertencia: {len(inconsistencias)} registros con subtotales inconsistentes")
    # Puedes corregir o investigar estos casos

# Validar rangos de valores
df = df[(df['cantidad'] > 0) & (df['precio_unitario'] > 0) & (df['total_venta'] > 0)]
# cambiar el total_venta
df['total_venta'] = df['cantidad'] * df['precio_unitario']
# Estandarizar categor√≠as/texto
df['metodo_pago'] = df['metodo_pago'].str.upper().str.strip()
df['categoria'] = df['categoria'].str.upper().str.strip()
df['producto_nombre'] = df['producto_nombre'].str.title()

"""### 4. Preparaci√≥n para An√°lisis Espec√≠ficos

#### Para productos m√°s vendidos/baja rotaci√≥n:
"""

productos_analisis = df.groupby(['producto_id', 'producto_nombre', 'categoria']).agg(
    unidades_vendidas=('cantidad', 'sum'),
    venta_total=('subtotal', 'sum'),
    frecuencia_ventas=('venta_id', 'count'),
    ultima_venta=('fecha_hora', 'max')
).reset_index()

# Calcular d√≠as desde √∫ltima venta
#productos_analisis['dias_sin_vender'] = (pd.to_datetime('today') - productos_analisis['ultima_venta']).dt.days

"""#### Para tendencias estacionales:"""

tendencias_mensuales = df.groupby(['a√±o', 'mes', 'categoria']).agg(
    venta_total=('subtotal', 'sum'),
    transacciones=('venta_id', 'count')
).reset_index()

# Calcular crecimiento interanual
tendencias_mensuales['venta_mes_anterior'] = tendencias_mensuales.groupby(['mes', 'categoria'])['venta_total'].shift(1)
tendencias_mensuales['crecimiento_interanual'] = (tendencias_mensuales['venta_total'] - tendencias_mensuales['venta_mes_anterior']) / tendencias_mensuales['venta_mes_anterior'] * 100

df.info()

"""#### Para patrones de compra por festivos:"""

comportamiento_festivos = df.groupby(['franja_horaria', 'categoria']).agg(
    venta_promedio=('subtotal', 'mean'),
    cantidad_transacciones=('venta_id', 'count')
).reset_index()



"""### 5. Optimizaci√≥n del DataFrame"""

# Reducir tama√±o del DataFrame cambiando tipos de datos
df['venta_id'] = df['venta_id'].astype('int32')
df['cliente_id'] = df['cliente_id'].astype('int32')
df['producto_id'] = df['producto_id'].astype('int32')

# Columnas categ√≥ricas a category
categorical_cols = ['metodo_pago', 'categoria', 'tipo_dia', 'dia_semana', 'franja_horaria', 'clasificacion_abc']
for col in categorical_cols:
    df[col] = df[col].astype('category')

# Eliminar columnas temporales si es necesario
#df = df.drop(columns=['subtotal_calculado'])

df.info()



"""# Analisis EDA

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



"""### Total Venta"""

import matplotlib.pyplot as plt
import seaborn as sns

# Estilo general
sns.set(style='whitegrid')

plt.figure(figsize=(12, 6))
# Histograma con KDE (l√≠nea de densidad)
sns.histplot(df['total_venta'], bins=50, kde=True, color='skyblue', edgecolor='white', alpha=0.8)

# T√≠tulo y etiquetas
plt.title('Distribuci√≥n del Total de Venta', fontsize=16, fontweight='bold')
plt.xlabel('Total de Venta', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# L√≠neas de grid
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

plt.tight_layout()
plt.show()

df["total_venta"].describe()

"""### Metodo de pago"""

plt.figure(figsize=(10, 6))  # Aumentamos el tama√±o del gr√°fico para mayor claridad

# Usamos un color personalizado y un esquema para ordenar por frecuencia
sns.countplot(data=df, x='metodo_pago', palette='Set2', order=df['metodo_pago'].value_counts().index)

# T√≠tulo y etiquetas con fuentes ajustadas
plt.title('Frecuencia de M√©todos de Pago', fontsize=16, fontweight='bold')
plt.xlabel('M√©todo de Pago', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# A√±adir el conteo encima de las barras
for p in plt.gca().patches:
    plt.gca().annotate(f'{p.get_height()}',
                       (p.get_x() + p.get_width() / 2., p.get_height()),
                       ha='center', va='center',
                       fontsize=12, color='black',
                       xytext=(0, 9), textcoords='offset points')

# Roto las etiquetas del eje X para mayor claridad
plt.xticks(rotation=45, ha='right', fontsize=11)

# A√±adir l√≠neas de grid para facilitar la visualizaci√≥n
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar el gr√°fico
plt.tight_layout()
plt.show()



"""### Categoria de productos"""

plt.figure(figsize=(20, 6))  # Aumentamos el tama√±o para mejor claridad

# Gr√°fico de barras con colores y ordenados por frecuencia
sns.countplot(data=df, x='categoria', order=df['categoria'].value_counts().index, palette='Set2')

# T√≠tulo y etiquetas con fuentes ajustadas
plt.title('Frecuencia de Categor√≠as de Productos', fontsize=16, fontweight='bold')
plt.xlabel('Categor√≠a', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# A√±adir el conteo encima de las barras
for p in plt.gca().patches:
    plt.gca().annotate(f'{p.get_height()}',
                       (p.get_x() + p.get_width() / 2., p.get_height()),
                       ha='center', va='center',
                       fontsize=12, color='black',
                       xytext=(0, 9), textcoords='offset points')

# Roto las etiquetas del eje X para mejor legibilidad
plt.xticks(rotation=45, ha='right', fontsize=11)

# A√±adir l√≠neas de grid horizontales para mejorar la legibilidad
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Mostrar el gr√°fico
plt.tight_layout()
plt.show()



"""### Precios unitarios"""

plt.figure(figsize=(8, 4))  # Aumentamos el tama√±o para mejor claridad

# Boxplot con color personalizado
sns.boxplot(data=df, x='precio_unitario', color='skyblue', fliersize=6, linewidth=1.5, palette='Blues')

# T√≠tulo y etiquetas con fuentes ajustadas
plt.title('Boxplot de Precios Unitarios', fontsize=16, fontweight='bold')
plt.xlabel('Precio Unitario', fontsize=12)

# A√±adir l√≠neas de grid horizontales
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Mostrar el gr√°fico
plt.tight_layout()
plt.show()

df["precio_unitario"].describe()

"""## Relacion entre variables

### Cantidad y total_venta
"""

plt.figure(figsize=(10, 6))

# Gr√°fico de dispersi√≥n con ajustes de color, tama√±o y transparencia
sns.scatterplot(data=df, x='cantidad', y='total_venta', color='royalblue', alpha=0.6, s=50)

# T√≠tulo y etiquetas con fuentes ajustadas
plt.title('Relaci√≥n entre Cantidad y Total de Venta', fontsize=16, fontweight='bold')
plt.xlabel('Cantidad', fontsize=12)
plt.ylabel('Total Venta', fontsize=12)

# A√±adir l√≠nea de tendencia (opcional)
sns.regplot(data=df, x='cantidad', y='total_venta', scatter=False, color='orange', line_kws={"linewidth":2, "linestyle":"--"})

# L√≠neas de grid para mejor interpretaci√≥n
plt.grid(True, linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Ajustar la disposici√≥n para que todo se vea bien
plt.tight_layout()

# Mostrar el gr√°fico
plt.show()

df.head(10)

"""### Correlacion entre variables numericas"""

# Calcular la correlaci√≥n
corr = df[['total_venta', 'cantidad', 'precio_unitario', 'subtotal']].corr()

# Crear el gr√°fico
plt.figure(figsize=(10, 8))

# Mapa de calor mejorado
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, linecolor='black', cbar_kws={'shrink': 0.8}, annot_kws={'size': 12, 'weight': 'bold', 'color': 'black'})

# T√≠tulo y etiquetas
plt.title('Mapa de Calor de Correlaciones', fontsize=16, fontweight='bold')
plt.xticks(rotation=45, fontsize=12)
plt.yticks(rotation=45, fontsize=12)

# Ajustar disposici√≥n para evitar superposici√≥n
plt.tight_layout()

# Mostrar el gr√°fico
plt.show()



"""### analisis temporal fecha_hora"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Convertir fecha_hora a tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])

# Crear nuevas columnas para el a√±o y el mes
df['anio'] = df['fecha_hora'].dt.year
df['mes'] = df['fecha_hora'].dt.month

# Agrupar los datos por a√±o y mes, y obtener la suma de las ventas
df_ventas = df.groupby(['anio', 'mes'])['total_venta'].sum().reset_index()

# Configurar el gr√°fico
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_ventas, x='mes', y='total_venta', hue='anio', marker='o', palette='tab10', lw=2)

# Mejorar la visualizaci√≥n
plt.title('Ventas Mensuales por A√±o')
plt.xlabel('Mes')
plt.ylabel('Total de Ventas ($)')
plt.xticks(ticks=range(1, 13), labels=['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic'])
plt.legend(title='A√±o', loc='upper left')
plt.grid(True)

# Mostrar el gr√°fico
plt.tight_layout()
plt.show()



"""## Outliers y limpieza de datos"""

# Eliminar outliers en total_venta (Ejemplo de eliminar ventas por encima del percentil 99)
q_high = df['total_venta'].quantile(0.99)
df = df[df['total_venta'] <= q_high]

len(df)

"""# 1: Indentificar los productos mas vendidos y los de baja rotacion para optimizar la gestion de inventario.

## Aplicacion de algoritmo FP-Grow
"""

pip install mlxtend

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, association_rules

df.info()

df = df.dropna(subset=["producto_nombre"])
df['producto_nombre'] = df['producto_nombre'].str.strip().str.lower()
transaction = df.groupby("venta_id")["producto_nombre"].apply(list).tolist()

#transaction
len(transaction)
#print([t for t in transaction[:10] if len(t) > 1])  # Verifica que no sean todos de un solo producto

"""## 2.-Convertir los datos en formato binario"""

# Convertir transacciones en formato binario
te = TransactionEncoder()
te_ary = te.fit(transaction).transform(transaction)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

"""## 3.- Aplicacion de  FP-Growth"""

# Si saca los datos satisfactoriamente, asi que debemos manipular la bd, especialmente los datos ..
# Unificar pan molde algo, con pan molde otro,, para que se unifiquen ojito...
# Aplicar FP-Growth con un umbral m√≠nimo de frecuencia
frequent_itemsets = fpgrowth(df_encoded, min_support=0.009, use_colnames=True)

len(frequent_itemsets)
# Mostrar solo conjuntos de productos con m√°s de 1 √≠tem
#frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: len(x) > 1)]

frequent_itemsets.sort_values(by='support', ascending=False).head(214)

# Generar reglas de asociaci√≥n
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.03)

# Ordenar por confianza
rules = rules.sort_values(by='confidence', ascending=False)

# Mostrar las reglas como frases legibles
for _, row in rules.iterrows():
    antecedent = ', '.join(list(row['antecedents']))
    consequent = ', '.join(list(row['consequents']))
    support = row['support']
    confidence = row['confidence']
    lift = row['lift']

    print(f"üõí Si compra {antecedent} ‚ûú tambi√©n compra {consequent} "
          f"(soporte: {support:.3f}, confianza: {confidence:.2f}, lift: {lift:.2f})")

producto_frecuencia = df['producto_nombre'].value_counts()
print(producto_frecuencia.head())  # Los m√°s vendidos
print(producto_frecuencia.tail())  # Los menos vendidos

"""## 4.- Generar Reglas de Asociacion"""

from mlxtend.frequent_patterns import association_rules

# Generar reglas de asociaci√≥n a partir de los conjuntos frecuentes
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=0.01)

# Ordenar por confianza para ver las reglas m√°s fuertes
rules.sort_values(by="confidence", ascending=False).head(10)

"""## Interpretar los Resultados

## Encontrar los productos Mas vendidos
"""

productos_populares = frequent_itemsets.sort_values(by="support", ascending=False).head(10)
productos_populares

"""## Indentificar Productos de Baja Rotacion"""

productos_baja_rotacion = frequent_itemsets[frequent_itemsets["support"] < 0.005]
productos_baja_rotacion



"""# 2 objetivo especifico:Tendencias estacionales y su impacto en la demada de productos para mejorar la planificacion de compras."""

# Asegurar que la columna es tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], errors='coerce')

# Eliminar filas con fechas inv√°lidas
df = df.dropna(subset=['fecha_hora'])

# Establecer como √≠ndice
df.set_index("fecha_hora", inplace=True)

# Ordenar por fecha
df = df.sort_index()

# Resample diario
df_daily = df.resample("D").sum()

# Llenar NaN con 0 si es necesario
df_daily.fillna(0, inplace=True)

df = df_daily.reset_index()
df["fecha_hora"] = df["fecha_hora"].replace("0000-00-00 00:00:00", pd.NaT)
df["fecha_hora"] = pd.to_datetime(df["fecha_hora"])

df['a√±o'] = df['fecha_hora'].dt.year
df['mes'] = df['fecha_hora'].dt.month
df['d√≠a'] = df['fecha_hora'].dt.day
df['d√≠a_semana'] = df['fecha_hora'].dt.dayofweek  # 0: Lunes, 6: Domingo
df['semana'] = df['fecha_hora'].dt.isocalendar().week
df['trimestre'] = df['fecha_hora'].dt.quarter

df_monthly = df.groupby(['a√±o', 'mes']).agg({'total_venta': 'sum'}).reset_index()

"""## Modelos y Algoritmos para el Analisis de Tendencias Estacionales"""

import matplotlib.pyplot as plt

# Crear una columna con el formato "A√±o-Mes"
df_monthly["fecha"] = df_monthly["a√±o"].astype(str) + "-" + df_monthly["mes"].astype(str).str.zfill(2)

# Graficar
plt.figure(figsize=(14, 6))
plt.plot(df_monthly["fecha"], df_monthly["total_venta"], marker='o', linestyle='-', color='royalblue', label="Ventas reales")

plt.xlabel('Fecha (A√±o-Mes)')
plt.ylabel('Ventas Totales')
plt.title('Tendencia de Ventas Mensuales')
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()
plt.tight_layout()
plt.show()

"""## Descomposicion de Series Temporales"""

from statsmodels.tsa.seasonal import seasonal_decompose

# Descomposici√≥n aditiva
result = seasonal_decompose(df_monthly['total_venta'], model='additive', period=12)

import matplotlib.pyplot as plt

# Crear figura personalizada
fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)

# T√≠tulos personalizados
titles = ['Serie Original', 'Tendencia', 'Estacionalidad', 'Ruido (residuo)']
components = [result.observed, result.trend, result.seasonal, result.resid]
colors = ['royalblue', 'forestgreen', 'darkorange', 'crimson']

for i, ax in enumerate(axes):
    ax.plot(components[i], color=colors[i])
    ax.set_title(titles[i], fontsize=12, weight='bold')
    ax.grid(True, linestyle='--', alpha=0.5)

plt.suptitle('Descomposici√≥n de la Serie de Ventas Mensuales', fontsize=16, weight='bold')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.xticks(rotation=45)
plt.show()



"""## C: Modelos de Pronostricos de Ventas

### Modelos estaticos
"""

from statsmodels.tsa.arima.model import ARIMA
model = ARIMA(df_monthly['total_venta'], order=(5,1,0))
model_fit = model.fit()
df_monthly['pron√≥stico'] = model_fit.predict(start=100, end=120)

from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(df_monthly['total_venta'], order=(1,1,1), seasonal_order=(1,1,1,12))
model_fit = model.fit()
df_monthly['pron√≥stico'] = model_fit.predict(start=100, end=120)

"""### Modelos de Machine Learning"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100)
X = df_monthly[['a√±o', 'mes']]
y = df_monthly['total_venta']
rf.fit(X, y)
predicciones = rf.predict(X)

print(predicciones)

df_resultados = df_monthly.copy()
df_resultados["predicho"] = predicciones

print(df_resultados[["a√±o", "mes", "total_venta", "predicho"]].head())

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
plt.plot(df_monthly.index, y, label='Real', marker='o')
plt.plot(df_monthly.index, predicciones, label='Predicci√≥n', marker='x')
plt.title("Total de ventas: Real vs Predicho")
plt.xlabel("Fecha")
plt.ylabel("Total de Venta")
plt.legend()
plt.grid(True)
plt.show()



"""# 2:objetivo especifico

## analisis mensual trimestral
"""

ventas_mensuales = df.groupby(['a√±o', 'mes', 'producto_nombre'])['cantidad'].sum().reset_index()
productos_top_mensuales = ventas_mensuales.sort_values(['a√±o', 'mes', 'cantidad'], ascending=[True, True, False])

ventas_trimestrales = df.groupby(['a√±o', 'trimestre', 'producto_nombre'])['cantidad'].sum().reset_index()
productos_top_trimestrales = ventas_trimestrales.sort_values(['a√±o', 'trimestre', 'cantidad'], ascending=[True, True, False])

import seaborn as sns
import matplotlib.pyplot as plt

# Top 5 productos m√°s vendidos en todos los meses
top_productos = df.groupby('producto_nombre')['cantidad'].sum().nlargest(4).index.tolist()
filtro_top = df[df['producto_nombre'].isin(top_productos)]

ventas_mensuales_top = filtro_top.groupby(['a√±o', 'mes', 'producto_nombre'])['cantidad'].sum().reset_index()

plt.figure(figsize=(12,6))
sns.lineplot(data=ventas_mensuales_top, x='mes', y='cantidad', hue='producto_nombre', style='a√±o', markers=True)
plt.title('Tendencia mensual de los productos m√°s vendidos')
plt.xlabel('Mes')
plt.ylabel('Cantidad vendida')
plt.grid(True)
plt.show()

"""## Analisis por fias de la semaana o franja horaria"""

ventas_dia_semana = df.groupby(['dia_semana', 'producto_nombre'])['cantidad'].sum().reset_index()
ventas_dia_semana = ventas_dia_semana.sort_values(['dia_semana', 'cantidad'], ascending=[True, False])

ventas_franja = df.groupby(['franja_horaria', 'producto_nombre'])['cantidad'].sum().reset_index()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Diccionario de traducci√≥n ingl√©s-espa√±ol
dias_traduccion = {
    'Monday': 'Lunes',
    'Tuesday': 'Martes',
    'Wednesday': 'Mi√©rcoles',
    'Thursday': 'Jueves',
    'Friday': 'Viernes',
    'Saturday': 'S√°bado',
    'Sunday': 'Domingo'
}

# Orden correcto de los d√≠as
orden_dias = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']

# 1. Traducir los d√≠as al espa√±ol
ventas_dia_semana['dia_semana'] = ventas_dia_semana['dia_semana'].map(dias_traduccion)

# 2. Convertir a categor√≠a ordenada
ventas_dia_semana['dia_semana'] = pd.Categorical(
    ventas_dia_semana['dia_semana'],
    categories=orden_dias,
    ordered=True
)

# 3. Crear el gr√°fico
plt.figure(figsize=(10, 5))
sns.barplot(
    data=ventas_dia_semana,
    x='dia_semana',
    y='cantidad',
    palette='Blues_d',
    order=orden_dias  # Asegurar el orden correcto
)

plt.title('Ventas totales por d√≠a de la semana')
plt.ylabel('Cantidad vendida')
plt.xlabel('D√≠a de la semana')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Diccionario de traducci√≥n ingl√©s-espa√±ol
dias_traduccion = {
    'Monday': 'Lunes',
    'Tuesday': 'Martes',
    'Wednesday': 'Mi√©rcoles',
    'Thursday': 'Jueves',
    'Friday': 'Viernes',
    'Saturday': 'S√°bado',
    'Sunday': 'Domingo'
}

# Orden correcto de los d√≠as
orden_dias = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado', 'Domingo']

# 1. Traducir los d√≠as al espa√±ol en el DataFrame original
df['dia_semana'] = df['dia_semana'].map(dias_traduccion)

# 2. Preparar los datos para el heatmap
heat_data = df.groupby(['franja_horaria', 'dia_semana'])['cantidad'].sum().unstack().fillna(0)

# 3. Reordenar las columnas seg√∫n el orden de la semana
heat_data = heat_data[orden_dias]

# 4. Crear el heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(
    heat_data,
    cmap='YlGnBu',
    annot=True,
    fmt='.0f',
    linewidths=.5,
    cbar_kws={'label': 'Cantidad Vendida'}
)

plt.title('Mapa de Calor: Ventas por Franja Horaria y D√≠a de la Semana', pad=20, fontsize=14)
plt.ylabel('Franja Horaria', fontsize=12)
plt.xlabel('D√≠a de la Semana', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""## Analisis en fechas festivas"""

# Suponiendo que tienes una lista de feriados:
feriados = [
    # 2021
    "2021-03-01", "2021-03-02", "2021-03-03", "2021-03-04", "2021-03-05", "2021-03-06", "2021-03-07", "2021-03-08",
    "2021-03-03", "2021-03-04", "2021-04-17", "2021-04-18", "2021-06-21", "2021-07-08", "2021-08-05", "2021-08-06", "2021-12-30", "2021-12-31",

    # 2022
    "2022-03-01", "2022-03-02", "2022-03-03", "2022-03-04", "2022-03-05", "2022-03-06", "2022-03-07", "2022-03-08",
    "2022-03-03", "2022-03-04", "2022-04-17", "2022-04-18", "2022-06-21", "2022-07-08", "2022-08-05", "2022-08-06", "2022-12-30", "2022-12-31",

    # 2023
    "2023-03-01", "2023-03-02", "2023-03-03", "2023-03-04", "2023-03-05", "2023-03-06", "2023-03-07", "2023-03-08",
    "2023-03-03", "2023-03-04", "2023-04-17", "2023-04-18", "2023-06-21", "2023-07-08", "2023-08-05", "2023-08-06", "2023-12-30", "2023-12-31",

    # 2024
    "2024-03-01", "2024-03-02", "2024-03-03", "2024-03-04", "2024-03-05", "2024-03-06", "2024-03-07", "2024-03-08",
    "2024-03-03", "2024-03-04", "2024-04-17", "2024-04-18", "2024-06-21", "2024-07-08", "2024-08-05", "2024-08-06", "2024-12-30", "2024-12-31",

    # 2025
    "2025-03-01", "2025-03-02", "2025-03-03", "2025-03-04", "2025-03-05", "2025-03-06", "2025-03-07", "2025-03-08",
    "2025-03-03", "2025-03-04", "2025-04-17", "2025-04-18", "2025-06-21", "2025-07-08", "2025-08-05", "2025-08-06", "2025-12-30", "2025-12-31"
]
df['es_festivo'] = df['fecha'].isin(feriados)
ventas_festivos = df[df['es_festivo']].groupby('producto_nombre')['cantidad'].sum().reset_index()
top_festivos = ventas_festivos.sort_values('cantidad', ascending=False).head(10)



plt.figure(figsize=(10,5))
sns.barplot(data=top_festivos, x='cantidad', y='producto_nombre', palette='viridis')
plt.title('Top productos m√°s vendidos en fechas festivas')
plt.xlabel('Cantidad vendida')
plt.ylabel('Producto')
plt.show()

"""## Visualizacion"""

import seaborn as sns
import matplotlib.pyplot as plt

ventas_mensuales_simple = df.groupby(['mes'])['cantidad'].sum().reset_index()

plt.figure(figsize=(10,5))
sns.lineplot(data=ventas_mensuales_simple, x='mes', y='cantidad', marker='o')
plt.title('Tendencia de ventas mensuales')
plt.xlabel('Mes')
plt.ylabel('Cantidad vendida')
plt.xticks(range(1,13))
plt.grid(True)
plt.show()





"""# 3:objetivo especifico: Analizar los patrones de compra de los clientes en diferentes periodos y fechas festivas para anticipar la demanda y evitar problemas de sobresstock o desabastecimiento.

### Aplacion de ARIMA para determinacion de fechas donde se vendio mas
"""

# Asegurar que la columna es tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], errors='coerce')

# Eliminar filas con fechas inv√°lidas
df = df.dropna(subset=['fecha_hora'])

# Establecer como √≠ndice
df.set_index("fecha_hora", inplace=True)

# Ordenar por fecha
df = df.sort_index()
# Resample diario
df_daily = df.resample("D").sum()

# Llenar NaN con 0 si es necesario
df_daily.fillna(0, inplace=True)

df = df_daily.reset_index()
df["fecha_hora"] = df["fecha_hora"].replace("0000-00-00 00:00:00", pd.NaT)
df["fecha_hora"] = pd.to_datetime(df["fecha_hora"])

"""### Graficacion de la serie temporal"""

import matplotlib.pyplot as plt

# Graficar la serie temporal de ventas diarias
plt.figure(figsize=(12, 6))
plt.plot(df_daily, label="Ventas diarias", color="blue")
plt.xlabel("Fecha")
plt.ylabel("Total de ventas")
plt.title("Ventas diarias en el supermercado")
plt.legend()
plt.show()

"""### Analisis de la serie temporal"""

import matplotlib.pyplot as plt
import statsmodels.api as sm

# Descomposici√≥n de la serie temporal
decomposition = sm.tsa.seasonal_decompose(df_daily, model="additive")

# Graficamos la descomposici√≥n
fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))
decomposition.observed.plot(ax=ax1, title="Ventas diarias")
decomposition.trend.plot(ax=ax2, title="Tendencia")
decomposition.seasonal.plot(ax=ax3, title="Estacionalidad")
decomposition.resid.plot(ax=ax4, title="Ruido")
plt.tight_layout()
plt.show()

"""### Aplicaion de ARIMA"""

from statsmodels.tsa.stattools import adfuller

# Prueba de Dickey-Fuller para ver si la serie es estacionaria
result = adfuller(df_daily["total_venta"])
print("Valor p:", result[1])  # Si es menor a 0.05, la serie es estacionaria

"""### Encontrar los parametros optimos de ARIMA"""

import pmdarima as pm
# Seleccionar los mejores par√°metros de ARIMA autom√°ticamente
model = pm.auto_arima(df_daily, seasonal=True, m=7, trace=True, suppress_warnings=True)
print(model.summary())



"""### Entrenar el modelo de ARIMA"""

from statsmodels.tsa.arima.model import ARIMA

# Entrenar ARIMA con los par√°metros encontrados (ejemplo p=1, d=1, q=1)
modelo = ARIMA(df_daily["total_venta"], order=(1,1,1))
modelo_entrenado = modelo.fit()

# Mostrar resumen del modelo
print(modelo_entrenado.summary())

"""### Hacer predicciones futuras"""

# Predecir los pr√≥ximos 30 d√≠as
predicciones = modelo_entrenado.forecast(steps=30)

# Graficar predicciones
plt.figure(figsize=(12, 6))
plt.plot(df_daily, label="Ventas reales", color="blue")
plt.plot(predicciones, label="Predicci√≥n ARIMA", color="red")
plt.xlabel("Fecha")
plt.ylabel("Total de ventas")
plt.title("Predicci√≥n de ventas con ARIMA")
plt.legend()
plt.show()



"""# 3: objetivo"""

df.head()

"""## Comportamiento por dia de la semana"""

ventas_dia = df.groupby('dia_semana')['subtotal'].sum().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

plt.figure(figsize=(10, 6))
ventas_dia.plot(kind='bar', color='skyblue')
plt.title('Ventas totales por d√≠a de la semana')
plt.ylabel('Total vendido')
plt.xlabel('D√≠a de la semana')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("figura1_ventas_dia_semana.png")  # Para insertar en documento
plt.show()



"""## Comportamiento mensual de compras"""

ventas_mes = df.groupby(['a√±o', 'mes'])['subtotal'].sum().reset_index()

plt.figure(figsize=(12, 6))
sns.lineplot(data=ventas_mes, x='mes', y='subtotal', hue='a√±o', marker='o')
plt.title('Tendencia mensual de ventas por a√±o')
plt.xlabel('Mes')
plt.ylabel('Total vendido')
plt.xticks(range(1, 13))
plt.legend(title='A√±o')
plt.tight_layout()
plt.savefig("figura2_ventas_mensuales.png")
plt.show()



"""## Deteccion de fechas festivas con picos de venta"""

ventas_fecha = df.groupby('fecha')['subtotal'].sum().reset_index()
ventas_fecha['fecha'] = pd.to_datetime(ventas_fecha['fecha'])

# Detecci√≥n de picos (mayores a media + 2*std)
mean = ventas_fecha['subtotal'].mean()
std = ventas_fecha['subtotal'].std()
umbral = mean + 2 * std
picos = ventas_fecha[ventas_fecha['subtotal'] > umbral]

plt.figure(figsize=(14, 6))
plt.plot(ventas_fecha['fecha'], ventas_fecha['subtotal'], label='Ventas diarias')
plt.scatter(picos['fecha'], picos['subtotal'], color='red', label='Picos de venta')
plt.title('Ventas diarias con picos destacados')
plt.xlabel('Fecha')
plt.ylabel('Total vendido')
plt.legend()
plt.tight_layout()
plt.savefig("figura3_picos_festivos.png")
plt.show()

# Mostrar fechas pico
print("Fechas con ventas inusualmente altas:")
picos[['fecha', 'subtotal']]



"""## Analisis por franja horaria"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='franja_horaria', y='subtotal')
plt.title('Distribuci√≥n del subtotal por franja horaria')
plt.xlabel('Franja horaria')
plt.ylabel('Subtotal de venta')
plt.tight_layout()
plt.savefig("figura4_franja_horaria.png")
plt.show()





"""# 4:objetivo especifico: Desarrollo del dashobard

"""

df.sample(n=20)

len(df)

df.info()

df.to_csv("df_clean.csv",index=False)

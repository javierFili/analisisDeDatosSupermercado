# -*- coding: utf-8 -*-
"""LimpiezaDeDatos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yWbql0FnCICYVjMrcFxMTSNi9rqVrKCv

# Importacion del data set
"""

# prompt: conectar con google drive y extraer un archivo .cvs

from google.colab import drive
import pandas as pd

# Montar Google Drive
drive.mount('/content/drive')

# Ruta del archivo CSV en Google Drive
file_path = '/content/drive/MyDrive/ventas_completas.csv'  # Reemplaza 'your_file.csv' con el nombre real del archivo y la ruta correcta

# Leer el archivo CSV usando pandas
try:
  df = pd.read_csv(file_path)
  print("Archivo CSV leído exitosamente.")
  # Ahora puedes trabajar con el DataFrame 'df'
  print(df.head()) # Muestra las primeras filas del DataFrame
except FileNotFoundError:
  print(f"Error: El archivo '{file_path}' no se encontró en Google Drive.")
except pd.errors.ParserError:
  print(f"Error: No se pudo procesar el archivo '{file_path}' como un archivo CSV válido.")
except Exception as e:
  print(f"Ocurrió un error inesperado: {e}")
df = df.tail(-1)

df.isnull().sum()

df.head(20)

"""# Limpiesa y preprocesamiento

### 1 Limpieza Inicial de Datos
"""

import pandas as pd
import numpy as np

# Convertir fecha_hora a datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])

# Verificar y manejar valores nulos
print(df.isnull().sum())
df = df.dropna(subset=['venta_id', 'fecha_hora', 'total_venta', 'producto_id'])  # Columnas críticas

# Manejar clientes anónimos (si aplica)
df['cliente_id'] = df['cliente_id'].fillna(0)

df['cliente_nombre'] = df['cliente_nombre'].fillna('CLIENTE OCASIONAL')
#df = df.dropna(subset=["cliente_nombre"])
df['precio_unitario'] = df["precio_unitario"]*0.20
# Verificar duplicados
df = df.drop_duplicates()

df.head(20)

"""### 2.Ingeniería de Características para los Objetivos"""

# Extraer componentes de fecha para análisis temporal
df['fecha'] = df['fecha_hora'].dt.date
df['hora'] = df['fecha_hora'].dt.hour
df['dia_semana'] = df['fecha_hora'].dt.day_name()
df['mes'] = df['fecha_hora'].dt.month
df['trimestre'] = df['fecha_hora'].dt.quarter
df['año'] = df['fecha_hora'].dt.year

# Crear categorías de hora del día
df['franja_horaria'] = pd.cut(df['hora'],
                             bins=[0, 6, 12, 18, 24],
                             labels=['Madrugada', 'Mañana', 'Tarde', 'Noche'],
                             right=False)

# Clasificación ABC de productos (para gestión de inventario)
ventas_por_producto = df.groupby('producto_id')['cantidad'].sum().sort_values(ascending=False)
ventas_por_producto = ventas_por_producto.reset_index()
ventas_por_producto['porcentaje_acumulado'] = ventas_por_producto['cantidad'].cumsum() / ventas_por_producto['cantidad'].sum() * 100

# Asignar categorías ABC
def clasificar_abc(x):
    if x <= 80:
        return 'A'
    elif x <= 95:
        return 'B'
    else:
        return 'C'

ventas_por_producto['clasificacion_abc'] = ventas_por_producto['porcentaje_acumulado'].apply(clasificar_abc)

# Unir al DataFrame principal
df = df.merge(ventas_por_producto[['producto_id', 'clasificacion_abc']], on='producto_id', how='left')

"""### 3. Validación y Consistencia de Datos"""

# Verificar consistencia en cálculos numéricos
df['subtotal_calculado'] = df['cantidad'] * df['precio_unitario']
inconsistencias = df[abs(df['subtotal'] - df['subtotal_calculado']) > 0.01]
if not inconsistencias.empty:
    print(f"Advertencia: {len(inconsistencias)} registros con subtotales inconsistentes")
    # Puedes corregir o investigar estos casos

# Validar rangos de valores
df = df[(df['cantidad'] > 0) & (df['precio_unitario'] > 0) & (df['total_venta'] > 0)]
# cambiar el total_venta
df['total_venta'] = df['cantidad'] * df['precio_unitario']
# Estandarizar categorías/texto
df['metodo_pago'] = df['metodo_pago'].str.upper().str.strip()
df['categoria'] = df['categoria'].str.upper().str.strip()
df['producto_nombre'] = df['producto_nombre'].str.title()

"""### 4. Preparación para Análisis Específicos

#### Para productos más vendidos/baja rotación:
"""

productos_analisis = df.groupby(['producto_id', 'producto_nombre', 'categoria']).agg(
    unidades_vendidas=('cantidad', 'sum'),
    venta_total=('subtotal', 'sum'),
    frecuencia_ventas=('venta_id', 'count'),
    ultima_venta=('fecha_hora', 'max')
).reset_index()

# Calcular días desde última venta
#productos_analisis['dias_sin_vender'] = (pd.to_datetime('today') - productos_analisis['ultima_venta']).dt.days

"""#### Para tendencias estacionales:"""

tendencias_mensuales = df.groupby(['año', 'mes', 'categoria']).agg(
    venta_total=('subtotal', 'sum'),
    transacciones=('venta_id', 'count')
).reset_index()

# Calcular crecimiento interanual
tendencias_mensuales['venta_mes_anterior'] = tendencias_mensuales.groupby(['mes', 'categoria'])['venta_total'].shift(1)
tendencias_mensuales['crecimiento_interanual'] = (tendencias_mensuales['venta_total'] - tendencias_mensuales['venta_mes_anterior']) / tendencias_mensuales['venta_mes_anterior'] * 100

df.info()

"""#### Para patrones de compra por festivos:"""

comportamiento_festivos = df.groupby(['franja_horaria', 'categoria']).agg(
    venta_promedio=('subtotal', 'mean'),
    cantidad_transacciones=('venta_id', 'count')
).reset_index()



"""### 5. Optimización del DataFrame"""

# Reducir tamaño del DataFrame cambiando tipos de datos
df['venta_id'] = df['venta_id'].astype('int32')
df['cliente_id'] = df['cliente_id'].astype('int32')
df['producto_id'] = df['producto_id'].astype('int32')

# Columnas categóricas a category
categorical_cols = ['metodo_pago', 'categoria', 'tipo_dia', 'dia_semana', 'franja_horaria', 'clasificacion_abc']
for col in categorical_cols:
    df[col] = df[col].astype('category')

# Eliminar columnas temporales si es necesario
#df = df.drop(columns=['subtotal_calculado'])

df.info()



"""# Analisis EDA

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



"""### Total Venta"""

import matplotlib.pyplot as plt
import seaborn as sns

# Estilo general
sns.set(style='whitegrid')

plt.figure(figsize=(12, 6))
# Histograma con KDE (línea de densidad)
sns.histplot(df['total_venta'], bins=50, kde=True, color='skyblue', edgecolor='white', alpha=0.8)

# Título y etiquetas
plt.title('Distribución del Total de Venta', fontsize=16, fontweight='bold')
plt.xlabel('Total de Venta', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# Líneas de grid
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

plt.tight_layout()
plt.show()

df["total_venta"].describe()

"""### Metodo de pago"""

plt.figure(figsize=(10, 6))  # Aumentamos el tamaño del gráfico para mayor claridad

# Usamos un color personalizado y un esquema para ordenar por frecuencia
sns.countplot(data=df, x='metodo_pago', palette='Set2', order=df['metodo_pago'].value_counts().index)

# Título y etiquetas con fuentes ajustadas
plt.title('Frecuencia de Métodos de Pago', fontsize=16, fontweight='bold')
plt.xlabel('Método de Pago', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# Añadir el conteo encima de las barras
for p in plt.gca().patches:
    plt.gca().annotate(f'{p.get_height()}',
                       (p.get_x() + p.get_width() / 2., p.get_height()),
                       ha='center', va='center',
                       fontsize=12, color='black',
                       xytext=(0, 9), textcoords='offset points')

# Roto las etiquetas del eje X para mayor claridad
plt.xticks(rotation=45, ha='right', fontsize=11)

# Añadir líneas de grid para facilitar la visualización
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Mostrar el gráfico
plt.tight_layout()
plt.show()



"""### Categoria de productos"""

plt.figure(figsize=(20, 6))  # Aumentamos el tamaño para mejor claridad

# Gráfico de barras con colores y ordenados por frecuencia
sns.countplot(data=df, x='categoria', order=df['categoria'].value_counts().index, palette='Set2')

# Título y etiquetas con fuentes ajustadas
plt.title('Frecuencia de Categorías de Productos', fontsize=16, fontweight='bold')
plt.xlabel('Categoría', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)

# Añadir el conteo encima de las barras
for p in plt.gca().patches:
    plt.gca().annotate(f'{p.get_height()}',
                       (p.get_x() + p.get_width() / 2., p.get_height()),
                       ha='center', va='center',
                       fontsize=12, color='black',
                       xytext=(0, 9), textcoords='offset points')

# Roto las etiquetas del eje X para mejor legibilidad
plt.xticks(rotation=45, ha='right', fontsize=11)

# Añadir líneas de grid horizontales para mejorar la legibilidad
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Mostrar el gráfico
plt.tight_layout()
plt.show()



"""### Precios unitarios"""

plt.figure(figsize=(8, 4))  # Aumentamos el tamaño para mejor claridad

# Boxplot con color personalizado
sns.boxplot(data=df, x='precio_unitario', color='skyblue', fliersize=6, linewidth=1.5, palette='Blues')

# Título y etiquetas con fuentes ajustadas
plt.title('Boxplot de Precios Unitarios', fontsize=16, fontweight='bold')
plt.xlabel('Precio Unitario', fontsize=12)

# Añadir líneas de grid horizontales
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Mostrar el gráfico
plt.tight_layout()
plt.show()

df["precio_unitario"].describe()

"""## Relacion entre variables

### Cantidad y total_venta
"""

plt.figure(figsize=(10, 6))

# Gráfico de dispersión con ajustes de color, tamaño y transparencia
sns.scatterplot(data=df, x='cantidad', y='total_venta', color='royalblue', alpha=0.6, s=50)

# Título y etiquetas con fuentes ajustadas
plt.title('Relación entre Cantidad y Total de Venta', fontsize=16, fontweight='bold')
plt.xlabel('Cantidad', fontsize=12)
plt.ylabel('Total Venta', fontsize=12)

# Añadir línea de tendencia (opcional)
sns.regplot(data=df, x='cantidad', y='total_venta', scatter=False, color='orange', line_kws={"linewidth":2, "linestyle":"--"})

# Líneas de grid para mejor interpretación
plt.grid(True, linestyle='--', alpha=0.7)

# Eliminar bordes innecesarios
sns.despine()

# Ajustar la disposición para que todo se vea bien
plt.tight_layout()

# Mostrar el gráfico
plt.show()

df.head(10)

"""### Correlacion entre variables numericas"""

# Calcular la correlación
corr = df[['total_venta', 'cantidad', 'precio_unitario', 'subtotal']].corr()

# Crear el gráfico
plt.figure(figsize=(10, 8))

# Mapa de calor mejorado
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, linecolor='black', cbar_kws={'shrink': 0.8}, annot_kws={'size': 12, 'weight': 'bold', 'color': 'black'})

# Título y etiquetas
plt.title('Mapa de Calor de Correlaciones', fontsize=16, fontweight='bold')
plt.xticks(rotation=45, fontsize=12)
plt.yticks(rotation=45, fontsize=12)

# Ajustar disposición para evitar superposición
plt.tight_layout()

# Mostrar el gráfico
plt.show()



"""### analisis temporal fecha_hora"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Convertir fecha_hora a tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])

# Crear nuevas columnas para el año y el mes
df['anio'] = df['fecha_hora'].dt.year
df['mes'] = df['fecha_hora'].dt.month

# Agrupar los datos por año y mes, y obtener la suma de las ventas
df_ventas = df.groupby(['anio', 'mes'])['total_venta'].sum().reset_index()

# Configurar el gráfico
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_ventas, x='mes', y='total_venta', hue='anio', marker='o', palette='tab10', lw=2)

# Mejorar la visualización
plt.title('Ventas Mensuales por Año')
plt.xlabel('Mes')
plt.ylabel('Total de Ventas ($)')
plt.xticks(ticks=range(1, 13), labels=['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic'])
plt.legend(title='Año', loc='upper left')
plt.grid(True)

# Mostrar el gráfico
plt.tight_layout()
plt.show()



"""## Outliers y limpieza de datos"""

# Eliminar outliers en total_venta (Ejemplo de eliminar ventas por encima del percentil 99)
q_high = df['total_venta'].quantile(0.99)
df = df[df['total_venta'] <= q_high]

len(df)

"""# 1: Indentificar los productos mas vendidos y los de baja rotacion para optimizar la gestion de inventario.

## Aplicacion de algoritmo FP-Grow
"""

pip install mlxtend

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, association_rules

df.info()

df = df.dropna(subset=["producto_nombre"])
df['producto_nombre'] = df['producto_nombre'].str.strip().str.lower()
transaction = df.groupby("venta_id")["producto_nombre"].apply(list).tolist()

#transaction
len(transaction)
#print([t for t in transaction[:10] if len(t) > 1])  # Verifica que no sean todos de un solo producto

"""## 2.-Convertir los datos en formato binario"""

# Convertir transacciones en formato binario
te = TransactionEncoder()
te_ary = te.fit(transaction).transform(transaction)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

"""## 3.- Aplicacion de  FP-Growth"""

# Si saca los datos satisfactoriamente, asi que debemos manipular la bd, especialmente los datos ..
# Unificar pan molde algo, con pan molde otro,, para que se unifiquen ojito...
# Aplicar FP-Growth con un umbral mínimo de frecuencia
frequent_itemsets = fpgrowth(df_encoded, min_support=0.009, use_colnames=True)

len(frequent_itemsets)
# Mostrar solo conjuntos de productos con más de 1 ítem
#frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: len(x) > 1)]

frequent_itemsets.sort_values(by='support', ascending=False).head(214)

# Generar reglas de asociación
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.03)

# Ordenar por confianza
rules = rules.sort_values(by='confidence', ascending=False)

# Mostrar las reglas como frases legibles
for _, row in rules.iterrows():
    antecedent = ', '.join(list(row['antecedents']))
    consequent = ', '.join(list(row['consequents']))
    support = row['support']
    confidence = row['confidence']
    lift = row['lift']

    print(f"🛒 Si compra {antecedent} ➜ también compra {consequent} "
          f"(soporte: {support:.3f}, confianza: {confidence:.2f}, lift: {lift:.2f})")

producto_frecuencia = df['producto_nombre'].value_counts()
print(producto_frecuencia.head())  # Los más vendidos
print(producto_frecuencia.tail())  # Los menos vendidos

"""## 4.- Generar Reglas de Asociacion"""

from mlxtend.frequent_patterns import association_rules

# Generar reglas de asociación a partir de los conjuntos frecuentes
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=0.01)

# Ordenar por confianza para ver las reglas más fuertes
rules.sort_values(by="confidence", ascending=False).head(10)

"""## Interpretar los Resultados

## Encontrar los productos Mas vendidos
"""

productos_populares = frequent_itemsets.sort_values(by="support", ascending=False).head(10)
productos_populares

"""## Indentificar Productos de Baja Rotacion"""

productos_baja_rotacion = frequent_itemsets[frequent_itemsets["support"] < 0.005]
productos_baja_rotacion



"""# 2 objetivo especifico:Tendencias estacionales y su impacto en la demada de productos para mejorar la planificacion de compras."""

# Asegurar que la columna es tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], errors='coerce')

# Eliminar filas con fechas inválidas
df = df.dropna(subset=['fecha_hora'])

# Establecer como índice
df.set_index("fecha_hora", inplace=True)

# Ordenar por fecha
df = df.sort_index()

# Resample diario
df_daily = df.resample("D").sum()

# Llenar NaN con 0 si es necesario
df_daily.fillna(0, inplace=True)

df = df_daily.reset_index()
df["fecha_hora"] = df["fecha_hora"].replace("0000-00-00 00:00:00", pd.NaT)
df["fecha_hora"] = pd.to_datetime(df["fecha_hora"])

df['año'] = df['fecha_hora'].dt.year
df['mes'] = df['fecha_hora'].dt.month
df['día'] = df['fecha_hora'].dt.day
df['día_semana'] = df['fecha_hora'].dt.dayofweek  # 0: Lunes, 6: Domingo
df['semana'] = df['fecha_hora'].dt.isocalendar().week
df['trimestre'] = df['fecha_hora'].dt.quarter

df_monthly = df.groupby(['año', 'mes']).agg({'total_venta': 'sum'}).reset_index()

"""## Modelos y Algoritmos para el Analisis de Tendencias Estacionales"""

import matplotlib.pyplot as plt

# Crear una columna con el formato "Año-Mes"
df_monthly["fecha"] = df_monthly["año"].astype(str) + "-" + df_monthly["mes"].astype(str).str.zfill(2)

# Graficar
plt.figure(figsize=(14, 6))
plt.plot(df_monthly["fecha"], df_monthly["total_venta"], marker='o', linestyle='-', color='royalblue', label="Ventas reales")

plt.xlabel('Fecha (Año-Mes)')
plt.ylabel('Ventas Totales')
plt.title('Tendencia de Ventas Mensuales')
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()
plt.tight_layout()
plt.show()

"""## Descomposicion de Series Temporales"""

from statsmodels.tsa.seasonal import seasonal_decompose

# Descomposición aditiva
result = seasonal_decompose(df_monthly['total_venta'], model='additive', period=12)

import matplotlib.pyplot as plt

# Crear figura personalizada
fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)

# Títulos personalizados
titles = ['Serie Original', 'Tendencia', 'Estacionalidad', 'Ruido (residuo)']
components = [result.observed, result.trend, result.seasonal, result.resid]
colors = ['royalblue', 'forestgreen', 'darkorange', 'crimson']

for i, ax in enumerate(axes):
    ax.plot(components[i], color=colors[i])
    ax.set_title(titles[i], fontsize=12, weight='bold')
    ax.grid(True, linestyle='--', alpha=0.5)

plt.suptitle('Descomposición de la Serie de Ventas Mensuales', fontsize=16, weight='bold')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.xticks(rotation=45)
plt.show()



"""## C: Modelos de Pronostricos de Ventas

### Modelos estaticos
"""

from statsmodels.tsa.arima.model import ARIMA
model = ARIMA(df_monthly['total_venta'], order=(5,1,0))
model_fit = model.fit()
df_monthly['pronóstico'] = model_fit.predict(start=100, end=120)

from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(df_monthly['total_venta'], order=(1,1,1), seasonal_order=(1,1,1,12))
model_fit = model.fit()
df_monthly['pronóstico'] = model_fit.predict(start=100, end=120)

"""### Modelos de Machine Learning"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100)
X = df_monthly[['año', 'mes']]
y = df_monthly['total_venta']
rf.fit(X, y)
predicciones = rf.predict(X)

print(predicciones)

df_resultados = df_monthly.copy()
df_resultados["predicho"] = predicciones

print(df_resultados[["año", "mes", "total_venta", "predicho"]].head())

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
plt.plot(df_monthly.index, y, label='Real', marker='o')
plt.plot(df_monthly.index, predicciones, label='Predicción', marker='x')
plt.title("Total de ventas: Real vs Predicho")
plt.xlabel("Fecha")
plt.ylabel("Total de Venta")
plt.legend()
plt.grid(True)
plt.show()



"""# 2:objetivo especifico

## analisis mensual trimestral
"""

ventas_mensuales = df.groupby(['año', 'mes', 'producto_nombre'])['cantidad'].sum().reset_index()
productos_top_mensuales = ventas_mensuales.sort_values(['año', 'mes', 'cantidad'], ascending=[True, True, False])

ventas_trimestrales = df.groupby(['año', 'trimestre', 'producto_nombre'])['cantidad'].sum().reset_index()
productos_top_trimestrales = ventas_trimestrales.sort_values(['año', 'trimestre', 'cantidad'], ascending=[True, True, False])

import seaborn as sns
import matplotlib.pyplot as plt

# Top 5 productos más vendidos en todos los meses
top_productos = df.groupby('producto_nombre')['cantidad'].sum().nlargest(4).index.tolist()
filtro_top = df[df['producto_nombre'].isin(top_productos)]

ventas_mensuales_top = filtro_top.groupby(['año', 'mes', 'producto_nombre'])['cantidad'].sum().reset_index()

plt.figure(figsize=(12,6))
sns.lineplot(data=ventas_mensuales_top, x='mes', y='cantidad', hue='producto_nombre', style='año', markers=True)
plt.title('Tendencia mensual de los productos más vendidos')
plt.xlabel('Mes')
plt.ylabel('Cantidad vendida')
plt.grid(True)
plt.show()

"""## Analisis por fias de la semaana o franja horaria"""

ventas_dia_semana = df.groupby(['dia_semana', 'producto_nombre'])['cantidad'].sum().reset_index()
ventas_dia_semana = ventas_dia_semana.sort_values(['dia_semana', 'cantidad'], ascending=[True, False])

ventas_franja = df.groupby(['franja_horaria', 'producto_nombre'])['cantidad'].sum().reset_index()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Diccionario de traducción inglés-español
dias_traduccion = {
    'Monday': 'Lunes',
    'Tuesday': 'Martes',
    'Wednesday': 'Miércoles',
    'Thursday': 'Jueves',
    'Friday': 'Viernes',
    'Saturday': 'Sábado',
    'Sunday': 'Domingo'
}

# Orden correcto de los días
orden_dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']

# 1. Traducir los días al español
ventas_dia_semana['dia_semana'] = ventas_dia_semana['dia_semana'].map(dias_traduccion)

# 2. Convertir a categoría ordenada
ventas_dia_semana['dia_semana'] = pd.Categorical(
    ventas_dia_semana['dia_semana'],
    categories=orden_dias,
    ordered=True
)

# 3. Crear el gráfico
plt.figure(figsize=(10, 5))
sns.barplot(
    data=ventas_dia_semana,
    x='dia_semana',
    y='cantidad',
    palette='Blues_d',
    order=orden_dias  # Asegurar el orden correcto
)

plt.title('Ventas totales por día de la semana')
plt.ylabel('Cantidad vendida')
plt.xlabel('Día de la semana')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Diccionario de traducción inglés-español
dias_traduccion = {
    'Monday': 'Lunes',
    'Tuesday': 'Martes',
    'Wednesday': 'Miércoles',
    'Thursday': 'Jueves',
    'Friday': 'Viernes',
    'Saturday': 'Sábado',
    'Sunday': 'Domingo'
}

# Orden correcto de los días
orden_dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']

# 1. Traducir los días al español en el DataFrame original
df['dia_semana'] = df['dia_semana'].map(dias_traduccion)

# 2. Preparar los datos para el heatmap
heat_data = df.groupby(['franja_horaria', 'dia_semana'])['cantidad'].sum().unstack().fillna(0)

# 3. Reordenar las columnas según el orden de la semana
heat_data = heat_data[orden_dias]

# 4. Crear el heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(
    heat_data,
    cmap='YlGnBu',
    annot=True,
    fmt='.0f',
    linewidths=.5,
    cbar_kws={'label': 'Cantidad Vendida'}
)

plt.title('Mapa de Calor: Ventas por Franja Horaria y Día de la Semana', pad=20, fontsize=14)
plt.ylabel('Franja Horaria', fontsize=12)
plt.xlabel('Día de la Semana', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""## Analisis en fechas festivas"""

# Suponiendo que tienes una lista de feriados:
feriados = [
    # 2021
    "2021-03-01", "2021-03-02", "2021-03-03", "2021-03-04", "2021-03-05", "2021-03-06", "2021-03-07", "2021-03-08",
    "2021-03-03", "2021-03-04", "2021-04-17", "2021-04-18", "2021-06-21", "2021-07-08", "2021-08-05", "2021-08-06", "2021-12-30", "2021-12-31",

    # 2022
    "2022-03-01", "2022-03-02", "2022-03-03", "2022-03-04", "2022-03-05", "2022-03-06", "2022-03-07", "2022-03-08",
    "2022-03-03", "2022-03-04", "2022-04-17", "2022-04-18", "2022-06-21", "2022-07-08", "2022-08-05", "2022-08-06", "2022-12-30", "2022-12-31",

    # 2023
    "2023-03-01", "2023-03-02", "2023-03-03", "2023-03-04", "2023-03-05", "2023-03-06", "2023-03-07", "2023-03-08",
    "2023-03-03", "2023-03-04", "2023-04-17", "2023-04-18", "2023-06-21", "2023-07-08", "2023-08-05", "2023-08-06", "2023-12-30", "2023-12-31",

    # 2024
    "2024-03-01", "2024-03-02", "2024-03-03", "2024-03-04", "2024-03-05", "2024-03-06", "2024-03-07", "2024-03-08",
    "2024-03-03", "2024-03-04", "2024-04-17", "2024-04-18", "2024-06-21", "2024-07-08", "2024-08-05", "2024-08-06", "2024-12-30", "2024-12-31",

    # 2025
    "2025-03-01", "2025-03-02", "2025-03-03", "2025-03-04", "2025-03-05", "2025-03-06", "2025-03-07", "2025-03-08",
    "2025-03-03", "2025-03-04", "2025-04-17", "2025-04-18", "2025-06-21", "2025-07-08", "2025-08-05", "2025-08-06", "2025-12-30", "2025-12-31"
]
df['es_festivo'] = df['fecha'].isin(feriados)
ventas_festivos = df[df['es_festivo']].groupby('producto_nombre')['cantidad'].sum().reset_index()
top_festivos = ventas_festivos.sort_values('cantidad', ascending=False).head(10)



plt.figure(figsize=(10,5))
sns.barplot(data=top_festivos, x='cantidad', y='producto_nombre', palette='viridis')
plt.title('Top productos más vendidos en fechas festivas')
plt.xlabel('Cantidad vendida')
plt.ylabel('Producto')
plt.show()

"""## Visualizacion"""

import seaborn as sns
import matplotlib.pyplot as plt

ventas_mensuales_simple = df.groupby(['mes'])['cantidad'].sum().reset_index()

plt.figure(figsize=(10,5))
sns.lineplot(data=ventas_mensuales_simple, x='mes', y='cantidad', marker='o')
plt.title('Tendencia de ventas mensuales')
plt.xlabel('Mes')
plt.ylabel('Cantidad vendida')
plt.xticks(range(1,13))
plt.grid(True)
plt.show()





"""# 3:objetivo especifico: Analizar los patrones de compra de los clientes en diferentes periodos y fechas festivas para anticipar la demanda y evitar problemas de sobresstock o desabastecimiento.

### Aplacion de ARIMA para determinacion de fechas donde se vendio mas
"""

# Asegurar que la columna es tipo datetime
df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], errors='coerce')

# Eliminar filas con fechas inválidas
df = df.dropna(subset=['fecha_hora'])

# Establecer como índice
df.set_index("fecha_hora", inplace=True)

# Ordenar por fecha
df = df.sort_index()
# Resample diario
df_daily = df.resample("D").sum()

# Llenar NaN con 0 si es necesario
df_daily.fillna(0, inplace=True)

df = df_daily.reset_index()
df["fecha_hora"] = df["fecha_hora"].replace("0000-00-00 00:00:00", pd.NaT)
df["fecha_hora"] = pd.to_datetime(df["fecha_hora"])

"""### Graficacion de la serie temporal"""

import matplotlib.pyplot as plt

# Graficar la serie temporal de ventas diarias
plt.figure(figsize=(12, 6))
plt.plot(df_daily, label="Ventas diarias", color="blue")
plt.xlabel("Fecha")
plt.ylabel("Total de ventas")
plt.title("Ventas diarias en el supermercado")
plt.legend()
plt.show()

"""### Analisis de la serie temporal"""

import matplotlib.pyplot as plt
import statsmodels.api as sm

# Descomposición de la serie temporal
decomposition = sm.tsa.seasonal_decompose(df_daily, model="additive")

# Graficamos la descomposición
fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8))
decomposition.observed.plot(ax=ax1, title="Ventas diarias")
decomposition.trend.plot(ax=ax2, title="Tendencia")
decomposition.seasonal.plot(ax=ax3, title="Estacionalidad")
decomposition.resid.plot(ax=ax4, title="Ruido")
plt.tight_layout()
plt.show()

"""### Aplicaion de ARIMA"""

from statsmodels.tsa.stattools import adfuller

# Prueba de Dickey-Fuller para ver si la serie es estacionaria
result = adfuller(df_daily["total_venta"])
print("Valor p:", result[1])  # Si es menor a 0.05, la serie es estacionaria

"""### Encontrar los parametros optimos de ARIMA"""

import pmdarima as pm
# Seleccionar los mejores parámetros de ARIMA automáticamente
model = pm.auto_arima(df_daily, seasonal=True, m=7, trace=True, suppress_warnings=True)
print(model.summary())



"""### Entrenar el modelo de ARIMA"""

from statsmodels.tsa.arima.model import ARIMA

# Entrenar ARIMA con los parámetros encontrados (ejemplo p=1, d=1, q=1)
modelo = ARIMA(df_daily["total_venta"], order=(1,1,1))
modelo_entrenado = modelo.fit()

# Mostrar resumen del modelo
print(modelo_entrenado.summary())

"""### Hacer predicciones futuras"""

# Predecir los próximos 30 días
predicciones = modelo_entrenado.forecast(steps=30)

# Graficar predicciones
plt.figure(figsize=(12, 6))
plt.plot(df_daily, label="Ventas reales", color="blue")
plt.plot(predicciones, label="Predicción ARIMA", color="red")
plt.xlabel("Fecha")
plt.ylabel("Total de ventas")
plt.title("Predicción de ventas con ARIMA")
plt.legend()
plt.show()



"""# 3: objetivo"""

df.head()

"""## Comportamiento por dia de la semana"""

ventas_dia = df.groupby('dia_semana')['subtotal'].sum().reindex(
    ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

plt.figure(figsize=(10, 6))
ventas_dia.plot(kind='bar', color='skyblue')
plt.title('Ventas totales por día de la semana')
plt.ylabel('Total vendido')
plt.xlabel('Día de la semana')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("figura1_ventas_dia_semana.png")  # Para insertar en documento
plt.show()



"""## Comportamiento mensual de compras"""

ventas_mes = df.groupby(['año', 'mes'])['subtotal'].sum().reset_index()

plt.figure(figsize=(12, 6))
sns.lineplot(data=ventas_mes, x='mes', y='subtotal', hue='año', marker='o')
plt.title('Tendencia mensual de ventas por año')
plt.xlabel('Mes')
plt.ylabel('Total vendido')
plt.xticks(range(1, 13))
plt.legend(title='Año')
plt.tight_layout()
plt.savefig("figura2_ventas_mensuales.png")
plt.show()



"""## Deteccion de fechas festivas con picos de venta"""

ventas_fecha = df.groupby('fecha')['subtotal'].sum().reset_index()
ventas_fecha['fecha'] = pd.to_datetime(ventas_fecha['fecha'])

# Detección de picos (mayores a media + 2*std)
mean = ventas_fecha['subtotal'].mean()
std = ventas_fecha['subtotal'].std()
umbral = mean + 2 * std
picos = ventas_fecha[ventas_fecha['subtotal'] > umbral]

plt.figure(figsize=(14, 6))
plt.plot(ventas_fecha['fecha'], ventas_fecha['subtotal'], label='Ventas diarias')
plt.scatter(picos['fecha'], picos['subtotal'], color='red', label='Picos de venta')
plt.title('Ventas diarias con picos destacados')
plt.xlabel('Fecha')
plt.ylabel('Total vendido')
plt.legend()
plt.tight_layout()
plt.savefig("figura3_picos_festivos.png")
plt.show()

# Mostrar fechas pico
print("Fechas con ventas inusualmente altas:")
picos[['fecha', 'subtotal']]



"""## Analisis por franja horaria"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='franja_horaria', y='subtotal')
plt.title('Distribución del subtotal por franja horaria')
plt.xlabel('Franja horaria')
plt.ylabel('Subtotal de venta')
plt.tight_layout()
plt.savefig("figura4_franja_horaria.png")
plt.show()





"""# 4:objetivo especifico: Desarrollo del dashobard

"""

df.sample(n=20)

len(df)

df.info()

df.to_csv("df_clean.csv",index=False)
